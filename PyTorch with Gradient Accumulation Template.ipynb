{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439,"referenced_widgets":["7ef49e743cb348cb9a85943899814052","fca6f4d8b7a1485b9bdc2408036f5cff","5516f6b18cc448b9b76cd9c88df7a34b","fa24083296b345fbbaa3a7b8c4aa984e","ebe627790b2a48ee91e553eb97393321","3ec60816fb4a4f42bd85cf069a2119ee","9abf28f0c87f4674a81265c853a29141","efce0ab573914db7a88e319c5bdf2b03","d0ebfdf7735344058202c399d75a4cc6","3ac686d295e7426e977a823d37e5e82f","6abae900dedc485d9b9d55fb944f67e7"]},"executionInfo":{"elapsed":76206,"status":"error","timestamp":1686518415554,"user":{"displayName":"Daniel Milne","userId":"04684571998595245943"},"user_tz":-60},"id":"QrDDZTHG7Q26","outputId":"98570283-81b5-4677-b06b-18f3da321151"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, precision_score\n","from tqdm.notebook import tqdm\n","import time\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Lists to store accuracy values for each epoch\n","metrics_train_accuracy = []\n","metrics_val_accuracy = []\n","metrics_train_loss = []\n","metrics_val_loss = []\n","metrics_epoch = []\n","\n","def display_graphs(epoch, accuracy, val_accuracy, loss, val_loss):\n","    \n","    if isinstance(loss, torch.Tensor):\n","        loss = loss.cpu()\n","\n","    loss = loss.detach().numpy()\n","\n","    metrics_epoch.append(epoch+1)\n","    metrics_train_accuracy.append(accuracy)\n","    metrics_val_accuracy.append(val_accuracy)\n","    metrics_train_loss.append(loss)\n","    metrics_val_loss.append(val_loss)\n","    \n","    if epoch != 0:\n","        fig, axs = plt.subplots(1, 2, figsize=(20, 6))  # Create a figure with two subplots\n","        # Plot the accuracy graph in the first subplot\n","        axs[0].plot(metrics_epoch, metrics_train_accuracy, label='Training Accuracy', marker='o')\n","        axs[0].plot(metrics_epoch, metrics_val_accuracy, label='Validation Accuracy', marker='o')\n","        axs[0].set_xlabel('Epoch')\n","        axs[0].set_ylabel('Accuracy')\n","        axs[0].set_title('Training and Validation Accuracy')\n","        axs[0].set_ylim(0.5, 1)\n","        axs[0].set_xlim(1, num_epochs)\n","        axs[0].set_xticks(range(1, num_epochs + 1))\n","        axs[0].grid(True, linestyle='--', alpha=0.5)\n","        axs[0].legend()\n","\n","        # Plot the loss graph in the second subplot\n","        axs[1].plot(metrics_epoch, metrics_train_loss, label='Training Loss', marker='o')\n","        axs[1].plot(metrics_epoch, metrics_val_loss, label='Validation Loss', marker='o')\n","        axs[1].set_xlabel('Epoch')\n","        axs[1].set_ylabel('Loss')\n","        axs[1].set_title('Training and Validation Loss')\n","        axs[1].set_ylim(0, 0.5)\n","        axs[1].set_xlim(1, num_epochs)\n","        axs[1].set_xticks(range(1, num_epochs + 1))\n","        axs[1].grid(True, linestyle='--', alpha=0.5)\n","        axs[1].legend()\n","\n","        plt.tight_layout()\n","        plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Parameters"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["num_classes = 6\n","batch_size = 4\n","num_epochs = 2\n","accumulation_steps = 2  # Number of steps to accumulate gradients before performing an optimizer step\n","evaluation_steps = 100  # Number of steps after which to evaluate the model\n","display_graphs_bool = True"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the model from https://pytorch.org/vision/0.8/models.html or make your own\n","model = models.inception_v3(weights=None)\n","\n","# Define optimizer\n","learning_rate = 0.001\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load data from the data directory using ImageFolder\n","data_dir = r\"\"\n","image_size = 299\n","\n","# 4. Define PyTorch Transforms and include them in ImageFolder\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor(),\n","    #transforms.Normalize((0.5,), (0.5,)\n","    transforms.Lambda(lambda x: x.clamp(0, 1))\n","])\n","\n","print(\"Loading dataset...\")\n","# Load the entire dataset\n","dataset = ImageFolder(data_dir, transform=transform)\n","print(\"Complete\")\n","\n","# Split the dataset into training and testing sets\n","train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n","\n","# Create DataLoaders\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available\n","\n","print(f\"Moving model to device ({device})...\")\n","model.to(device)  # Move the model to the device (CPU or GPU)\n","print(\"Complete\")\n","\n","print(\"Setting up model...\")\n","model.train()  # Set the model to training mode\n","\n","loss_function = nn.CrossEntropyLoss()  # Define the loss function\n","model.zero_grad()  # Reset gradients tensors\n","optimizer.zero_grad()  # Reset optimizer gradients\n","print(\"Complete\")\n","\n","total_steps = len(train_loader)  # Total number of steps in an epoch\n","\n","display_graphs_bool = True"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Display Some Images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find the total number of label types in the train dataset\n","label_types = np.unique([label for _, label in train_dataset])\n","num_label_types = len(label_types)\n","\n","# Display an image for each label type\n","fig, axs = plt.subplots(1, num_label_types, figsize=(10, 5))\n","\n","for i, label_type in enumerate(label_types):\n","    # Find the index of the first image with the current label type\n","    label_indices = [index for index, (_, label) in enumerate(train_dataset) if label == label_type]\n","    label_index = label_indices[0]\n","\n","    # Get the image and its label\n","    sample_image, sample_label = train_dataset[label_index]\n","    sample_image = sample_image.permute(1, 2, 0)  # Permute dimensions from (C, H, W) to (H, W, C)\n","\n","    # Display the image with its label\n","    axs[i].imshow(sample_image, cmap=\"gray\", vmin=0, vmax=1)\n","    axs[i].set_title(f\"Label: {sample_label}\")\n","    axs[i].axis(\"off\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Save Callback"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["checkpoint_dir = r\"Saves\"\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","def save_checkpoint(epoch, model, optimizer, loss, val_loss, accuracy, val_accuracy):\n","    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch+1}_loss_{loss:.4f}_vloss{val_loss:.4f}_acc_{accuracy:.4f}_vacc{val_accuracy:.4f}.pt')\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss\n","    }\n","    torch.save(checkpoint, checkpoint_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Beginning training...\")\n","for epoch in range(num_epochs):\n","    progress_bar = tqdm(train_loader, total=total_steps, leave=True)\n","\n","    total_correct = 0\n","    total_samples = 0\n","\n","    for i, (inputs, labels) in enumerate(progress_bar):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        predictions, _ = model(inputs)\n","        loss = loss_function(predictions, labels)\n","        loss = loss / accumulation_steps\n","        loss.backward()\n","\n","        if (i + 1) % accumulation_steps == 0:\n","            optimizer.step()\n","            model.zero_grad()\n","            optimizer.zero_grad()\n","\n","        _, predicted_labels = torch.max(predictions, 1)  # Move this line inside the loop\n","\n","        total_correct += (predicted_labels == labels).sum().item()  # Accumulate correct predictions\n","        total_samples += labels.size(0)  # Accumulate total samples\n","\n","        progress_bar.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","\n","    # Evaluate accuracy after the training loop\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0\n","        val_correct = 0\n","        val_samples = 0\n","\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            predictions = model(inputs)\n","            _, predicted_labels = torch.max(predictions, 1)\n","\n","            val_correct += (predicted_labels == labels).sum().item()  # Accumulate correct predictions\n","            val_samples += labels.size(0)  # Accumulate total samples\n","\n","            val_loss += loss_function(predictions, labels).item()\n","\n","        val_loss /= len(test_loader)\n","        val_accuracy = val_correct / val_samples if val_samples != 0 else 0.0\n","\n","\n","    model.train()\n","\n","    accuracy = total_correct / total_samples if total_samples != 0 else 0.0\n","\n","    loss /= total_steps\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss:.6f}, Acc: {accuracy:.4f}, Val Loss: {val_loss:.6f}, Val Acc: {val_accuracy:.4f}\")\n","    if display_graphs_bool == True:\n","        display_graphs(epoch, accuracy, val_accuracy, loss, val_loss)\n","\n","    # Save model checkpoint\n","    save_checkpoint(epoch, model, optimizer, loss, val_loss, accuracy, val_accuracy)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Make Single Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","model.eval()\n","test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","index = 0\n","input_image, label = test_dataset[index]\n","with torch.no_grad():\n","    input_image = input_image.to(device)\n","\n","    output = model(input_image.unsqueeze(0))\n","    _, predicted = torch.max(output, 1)\n","    predicted_label = predicted.item()\n","\n","image = input_image.squeeze().cpu().numpy()  # Move tensor to CPU with .cpu()\n","plt.imshow(image, cmap='gray', vmin=0, vmax=1)\n","plt.title(\"True label: {}, Predicted label: {}\".format(label, predicted_label))\n","plt.axis('off')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["X3L6hlx4A7hN"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"3ac686d295e7426e977a823d37e5e82f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ec60816fb4a4f42bd85cf069a2119ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5516f6b18cc448b9b76cd9c88df7a34b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_efce0ab573914db7a88e319c5bdf2b03","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0ebfdf7735344058202c399d75a4cc6","value":9}},"6abae900dedc485d9b9d55fb944f67e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ef49e743cb348cb9a85943899814052":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fca6f4d8b7a1485b9bdc2408036f5cff","IPY_MODEL_5516f6b18cc448b9b76cd9c88df7a34b","IPY_MODEL_fa24083296b345fbbaa3a7b8c4aa984e"],"layout":"IPY_MODEL_ebe627790b2a48ee91e553eb97393321"}},"9abf28f0c87f4674a81265c853a29141":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0ebfdf7735344058202c399d75a4cc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebe627790b2a48ee91e553eb97393321":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efce0ab573914db7a88e319c5bdf2b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa24083296b345fbbaa3a7b8c4aa984e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac686d295e7426e977a823d37e5e82f","placeholder":"​","style":"IPY_MODEL_6abae900dedc485d9b9d55fb944f67e7","value":" 9/20 [01:07&lt;01:16,  6.95s/it]"}},"fca6f4d8b7a1485b9bdc2408036f5cff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ec60816fb4a4f42bd85cf069a2119ee","placeholder":"​","style":"IPY_MODEL_9abf28f0c87f4674a81265c853a29141","value":"Epoch [1/5]:  45%"}}}}},"nbformat":4,"nbformat_minor":0}
